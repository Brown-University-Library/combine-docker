---
layout: default
title: Appendix - Deprecated Features
---
<h1>Deprecated Features</h1>

<p>Combine’s initial development included several experimental ideas. Many of these were expanded into its current feature set, but others ultimately weren’t central enough to Combine’s core features to merit full development. Or in some cases, they relied on older code that could not be maintained within the funding and development hours available to the project over time.</p> 

<p>The features below no longer appear in the interface, but the code has been left intact in case a future development effort decides to revisit them. Future groups looking for ways to improve Combine and build new functionality would do well to start here.</p><br />

<h2>Search</h2>

<p>Combine provides a global search box on its main navigation bar, at the top right of the screen:</p> 

<table>
  <tr>
    <td><img src="images/Part15-01-GlobalSearch.jpg" alt="Global search box" width="300" border="2"></td>
  </tr>
  <tr>
  	<td><em>Global search box in main Combine navigation bar</em></td>
  </tr>
</table

<p>The user can search mapped fields across all Records, in all Jobs. Clicking the search box without typing in a search term will return all Records. If a search term is used, it will be copied automatically into the smaller search box at the top right of the table displaying the search results. Modified searches can be done there, updating the results in near realtime.</p> 

<p>By default, global search looks for any token in the search string. In this case, it’s likely that and matched most of those records. The following will outline search options to narrow results.</p><br />

<h2>Global Search Options</h2>

<p>Clicking the blue “Show Options” button will open a panel offering additional search options:</p> 

<table>
  <tr>
    <td><img src="images/Part15-02-SearchOptionsPanel.jpg" alt="The opened Search Options panel" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>The opened Search Options panel</em></td>
  </tr>
</table

<p>The first section “Organizations, Record Groups, and Jobs” will apply filters to the search at those hierarchical levels and within the selected facets.</p> 

<p>A search can be narrowed still further by selecting a search type:</p> 

<ul>
  <li>any token</li>
  <ul>
    <li>matches any token from the search terms, and is NOT case-sensitive</li>
    <li>default search type</li>
    <li>The search terms provided are tokenized, and each term is searched. This is the most general search.</li>
  </ul>
  <li>exact phrase</li>
  <ul>
    <li>matches the exact phrase, and only the exact phrase, and IS case-sensitive</li>
    <li>This search type is case-sensitive, and searches the entire search phrase provided, against un-tokenzied fields for all Records</li>
  </ul>
  <li>wildcard</li>
  <ul>
    <li>allows for the inclusion of a * wildcard character, matching the entire phrase, and IS case-sensitive</li>
    <li>This search type can be particularly helpful for searching various identifiers in records, allowing the match of a sub-string in a field’s full, case-sensitive value.</li> 
    <li>For example, we can take a piece of the Record ID for these Records – 1881b4 – and find Records that match that string somewhere in a field. Note the wildcard character * on both sides of the search term, indicating the field value may begin with anything, end with anything, but must contain that sub-string 1881b4. Somewhat unsurprisingly, the results are the same.</li>
    <li><strong>Note:</strong> Even blank spaces must be captured by a wild card *. So, searching for public domain anywhere in a field would translate to *public*domain*.</li>
  </ul>
</ul>

<p>Global Search is searching the mapped fields for Records, which are stored in ElasticSearch. As such, the power (and complexity) of ElasticSearch is exposed here to some degree.</p><br />

<h3>Saving / Sharing Searches</h3>

<p>Note that when options are applied to the search with the “Apply Options” button, the URL is updated to reflect these new search options. If that URL is returned to, those search options are automatically parsed and applied, as indicated by the following message:</p> 

<table>
  <tr>
    <td><img src="images/Part15-03-SearchParameters.jpg" alt="Options applied to search from URL" width="500" border="2"></td>
  </tr>
  <tr>
  	<td><em>Options applied to search from URL</em></td>
  </tr>
</table

<p>This might be particularly helpful for saving or sharing searches with others.</p><br />

<h2>Analysis Jobs</h2>

<p>Analysis Jobs are a bit of an island. On the back-end, they are essentially Duplicate / Merge Jobs, and have the same input and configuration requirements. They can pull input Jobs from across Organizations and Records Groups.</p> 

<p>Analysis Jobs differ in that they do not exist within a Record Group. They are imagined to be ephemeral, disposable Jobs used entirely for analysis purposes.</p> 

<p>You can see previously run, or start a new Analysis Job, from the “Analysis” link from the top-most navigation.</p> 

<p>Below, is an example of an Analysis Job comparing two Jobs, from different Record Groups. This ability to pull Jobs from different Record Groups is shared with Merge Jobs. You can see only one Job in the table, but the entire lineage of what Jobs contribute to this Analysis Job. When the Analysis Job is deleted, none of the other Jobs will be touched (and currently, they are not aware of the Analysis Job in their own lineage).</p> 

<table>
  <tr>
    <td><img src="images/Part15-04-AnalysisJob.jpg" alt="Analysis Job showing analysis of two Jobs" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Analysis Job showing analysis of two Jobs, across two different Record Groups</em></td>
  </tr>
</table>

<h2>Analyzing Indexed Fields</h2>

<p>Undoubtedly one of Combine’s more interesting, confusing, and potentially powerful areas is the indexing of Record XML into ElasticSearch. This section will outline how that happens, and some possible insights that can be gleamed from the results.</p>

<h3>How and Why?</h3> 

<p>All Records in Combine store their raw metadata as XML in a Mongo database. With that raw metadata, are some other fields about validity, internal identifiers, etc., as they relate to the Record. But, because the metadata is still an opaque XML “blob” at this point, it does not allow for inspection or analysis. To this end, when all Jobs are run, all Records are also indexed in ElasticSearch.</p> 

<p>As many who have worked with complex metadata can attest to, flattening or mapping hierarchical metadata to a flat document store like ElasticSearch or Solr is difficult. Combine approaches this problem by generically flattening all elements in a Record’s XML document into XPath paths, which are converted into field names that are stored in ElasticSearch. This includes attributes as well, further dynamically defining the ElasticSearch field name.</p> 

<p>For example, the following XML metadata element:</p> 

<p><code>< mods:accessCondition type="useAndReproduction" ></code>This book is in the public domain.< /mods:accessCondition ></p>

<p>would become the following ElasticSearch field name:</p> 

<p><code>mods_accessCondition_@type_useAndReproduction</code></p>

<p>While mods_accessCondition_@type_useAndReproduction is not terribly pleasant to look at, it’s telling where this value came from inside the XML document. And most importantly, this generic XPath flattening approach can be applied across all XML documents that Combine might encounter.</p> 

<p>This “flattening”, aka “mapping”, of XML to fields that can be stored and readily queried in ElasticSearch is done through Field Mapping Configurations.</p><br />

<p><strong>Breakdown of indexed fields for a Job</strong></p>

<p>When viewing the details of a Job, the tab “Mapped Fields” shows a breakdown of all fields, for all records in this job, in a table. They can be thought of roughly as facets for the Job.</p> 

<table>
  <tr>
    <td><img src="images/Part15-05-FieldAnalysisTab.jpg" alt="Example of a field Analysis Job" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Example of Field Analysis tab from Job details, showing all indexed fields for a Job</em></td>
  </tr>
</table

<p>There is a button “What does these numbers mean?” that outlines what the various columns mean:</p> 

<table>
  <tr>
    <td><img src="images/Part15-06-CollapsibleExplanation.jpg" alt="Collapsible explanation of indexed fields breakdown table" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Collapsible explanation of indexed fields breakdown table</em></td>
  </tr>
</table

<p>All columns are sortable, and some are linked out to another view that drills further into that particular field. One way to drill down into a field is to click on the field name itself. This will present another view with values from that field. Below is doing that for the field mods_subject_topic:</p> 

<table>
  <tr>
    <td><img src="images/Part15-07-MetadataFieldAnalysis.jpg" alt="Drill down" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Drill down to mods_subject_topic indexed field</em></td>
  </tr>
</table

<p>At the top, you can see some high-level metrics that recreate numbers from the overview, such as:</p> 

<uL>
  <li>how many documents have this field  </li>
  <li>how many do not</li>
  <li>how many total values are there, remembering that a single document can have multiple values</li>
  <li>how many distinct values are there</li>
  <li>percentage of unique (distinct / total values)</li>
  <li>and percentage of all documents that have this field</li>
</ul>

<p>In the table, you can see actual values for the field, with counts across documents in this Job. In the last column, you can click to see Records that have or do not have this particular value for this particular field.</p> 

<p>Clicking into a subject like “fairy tales”, we get the following screen:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08-FieldAnalysisFairyTales.jpg" alt="Details for 'fairy tales'" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Details for “fairy tales” mods_subject_topic indexed field</em></td>
  </tr>
</table

<p>At this level, we have the option to click into individual Records.</p><br />

<h2>Configuration: Field Mapping</h2>

<p>Field Mapping is the process of mapping values from a Record’s source (probably a document in XML) to meaningful and analyzable key/value pairs that can be stored in ElasticSearch. Combine uses these mapped values in several ways:</p> 

<uL>
  <li>analyzing distribution of XML elements and values across Records</li>
  <li>exporting to mapped field reports</li>
  <li>for single Records, querying the DPLA API to confirm existence</li>
  <li>comparing Records against DPLA bulk data downloads</li>
  <li>and much more!</li>
</ul>

<p>To perform this mapping, Combine uses an internal library called XML2kvp, which stands for “XML to Key/Value Pairs”, to map XML to key/value JSON documents. Under the hood, XML2kvp uses xmltodict to parse the Record XML into a hierarchical dictionary, and then loops through that, creating fields based on the configurations below.</p><br/ >

<h3>I’ve mapped DC or MODS to Solr or ElasticSearch, why not do something similar?</h3>

<p>Each mapping is unique to support specific access, preservation, or analysis purposes. A finely tuned mapping for one metadata format or institution is likely to be unusable for another, even one in the same metadata format. Combine strives to be metadata format agnostic for harvesting, transformation, and analysis, and furthermore, performing these actions before a mapping has even been created or considered. To this end, a “generic” but customizable mapper was needed to take XML records and convert them into fields that can be used for developing an understanding about a group of Records.</p> 

<p>While applications like Solr and ElasticSearch more recently support hierarchical documents, and would likely support a straight XML to JSON converted document (with xmltodict, or Object Management Group (OMG)’s XML to JSON conversion standard), the attributes in XML give it a dimensionality beyond simple hierarchy, and can be critical to understanding the nature and values of a particular XML element. These direct mappings would function, but would not provide the same scannable, analysis of a group of XML records.</p> 

<p>XML2kvp provides a way to blindly map most any XML document, providing a broad overview of fields and structures, with the ability to further narrow and configure. A possible update/improvement would be the ability for users to upload mappers of their making (e.g. XSLT) that would result in a flat mapping, but that is currently not implemented.</p><br />

<h2>Field Mapping Configuration</h2>

<p>Combine maps a Record’s original document – likely XML – to key/value pairs suitable for ElasticSearch with a library called XML2kvp. When running a new Job, users can provide parameters to the XML2kvp parser in the form of JSON.</p> 

<p>Here’s an example of the default configurations:</p> 

<table>
  <tr>
    <td>
      <code>{<br />
&nbsp;"add_literals": {},<br />
&nbsp;"concat_values_on_all_fields": false,<br />
&nbsp;"concat_values_on_fields": {},<br />
&nbsp;"copy_to": {},<br />
&nbsp;"copy_to_regex": {},<br />
&nbsp;"copy_value_to_regex": {},<br />
&nbsp;"error_on_delims_collision": false,<br />
&nbsp;"exclude_attributes": [],<br />
&nbsp;"exclude_elements": [],<br />
&nbsp;"include_all_attributes": false,<br />
&nbsp;"include_attributes": [],<br />
&nbsp;"node_delim": "_",<br />
&nbsp;"ns_prefix_delim": "|",<br />
&nbsp;"remove_copied_key": true,<br />
&nbsp;"remove_copied_value": false,<br />
&nbsp;"remove_ns_prefix": false,<br />
&nbsp;"self_describing": false,<br />
&nbsp;"skip_attribute_ns_declarations": true,<br />
&nbsp;"skip_repeating_values": true,<br />
&nbsp;"split_values_on_all_fields": false,<br />
&nbsp;"split_values_on_fields": {}<br />
}</code>
    </td>
  </tr>
</table><br />

<p>Clicking the button “What do these configurations mean?” will provide information about each parameter, pulled form the XML2kvp JSON schema.</p> 

<p>The default is a safe bet to run Jobs, but configurations can be saved, retrieved, updated, and deleted from this screen as well.</p><br />

<h3>How does it work</h3>

<p>XML2kvp converts elements from XML to key/value pairs by converting hierarchy in the XML document to character delimiters.</p> 

<p>Take for example the following, “unique” XML:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08a-ExampleofUniqueXML.jpg" alt="image of xml for the example" width="800" border="2"></td>
  </tr>
</table>

<p>Converted with default options from XML2kvp, you would get the following key/value pairs in JSON form:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08b-ExampleofUniqueXML.jpg" alt="image of xml for the example" width="800" border="2"></td>
  </tr>
</table>

<p>Some things to notice…</p> 

<ul>
  <li>the XML root element <root> is present for all fields as root</li>
  <li>the XML hierarchy <root><foo><bar> repeats twice in the XML, but is collapsed into a single field root_foo_bar</li>
  <ul>
    <li>moreover, because skip_repeating_values is set to true, the value 42 shows up only once, if set to false we would see the value ('42', '42', '9393943')</li>
  </ul>
  <li>a distinct absence of all attributes from the original XML, this is because include_all_attributes is set to false by default.</li>
</ul>

<p>Running with include_all_attributes set to true, we see a more complex and verbose output, with @ in various field names, indicating attributes:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08c-ExampleofUniqueXML.jpg" alt="image of xml for the example" width="800" border="2"></td>
  </tr>
</table>

<p>A more familiar example may be Dublin Core XML:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08d-ExampleofUniqueXML.jpg" alt="image of xml for the example" width="800" border="2"></td>
  </tr>
</table>

<p>And with default configurations, would map to:</p> 

<table>
  <tr>
    <td><img src="images/Part15-08e-ExampleofUniqueXML.jpg" alt="image of xml for the example" width="800" border="2"></td>
  </tr>
</table><br />

<h3>Configurations</h3>

<p>Within Combine, the configurations passed to XML2kvp are referred to as “Field Mapper Configurations”, and like many other parts of Combine, can be named, saved, and updated in the database for later, repeated use. This following table describes the configurations that can be used for field mapping.</p> 

<table border="2">
  <tr>
    <th>Parameter</th>
    <th>Type</th>
    <th>Description</th>
  </tr>
  <tr>
    <td>add_literals</td>
    <td>object</td>
    <td>Key/value pairs for literals to mixin, e.g. foo:bar would create field foo witd value bar [Default: {}]</td>
  </tr>
  <tr>
    <td>capture_attribute_values</td>
    <td>array</td>
    <td>Array of attributes to capture values from and set as standalone field, e.g. if [age] is provided and encounters <foo age='42'/>, a field foo_@age@ would be created (note tde additional trailing @ to indicate an attribute value) witd tde value 42. [Default: [], Before: copy_to, copy_to_regex]</td>
  </tr>
  <tr>
    <td>concat_values_on_all_fields</td>
    <td>[boolean,``string``]</td>
    <td>Boolean or String to join all values from multivalued field on [Default: false]</td>
  </tr>
  <tr>
    <td>concat_values_on_fields</td>
    <td>object</td>
    <td>Key/value pairs for fields to concat on provided value, e.g. foo_bar:- if encountering foo_bar:[goober,``tronic``] would concatenate to foo_bar:goober-tronic [Default: {}]</td>
  </tr>
  <tr>
    <td>copy_to_regex</td>
    <td>object</td>
    <td>Key/value pairs to copy one field to anotder, optionally removing original field, based on regex match of field, e.g. .*foo:bar would copy create field bar and copy all values fields goober_foo and tronic_foo to bar. Note: Can also be used to remove fields by setting tde target field as false, e.g. .*bar:false, would remove fields matching regex .*bar [Default: {}]</td>
  </tr>
  <tr>
    <td>copy_to</td>
    <td>object</td>
    <td>Key/value pairs to copy one field to anotder, optionally removing original field, e.g. foo:bar would create field bar and copy all values when encountered for foo to bar, removing foo. However, tde original field can be retained by setting remove_copied_key to true. Note: Can also be used to remove fields by setting tde target field as false, e.g. ‘foo’:false, would remove field foo. [Default: {}]</td>
    <td>copy_value_to_regex</td>
    <td>object</td>
    <td>Key/value pairs tdat match values based on regex and copy to new field if matching, e.g. http.*:websites would create new field websites and copy http://exampl.com and https://example.org to new field websites [Default: {}]</td>
  </tr>
  <tr>
    <td>error_on_delims_collision</td>
    <td>boolean</td>
    <td>Boolean to raise DelimiterCollision exception if delimiter strings from eitder node_delim or ns_prefix_delim collide witd field name or field value (false by default for permissive mapping, but can be helpful if collisions are essential to detect) [Default: false]</td>
  </tr>
  <tr>
    <td>exclude_attributes</td>
    <td>array</td>
    <td>Array of attributes to skip when creating field names, e.g. [baz] when encountering XML <foo><bar baz='42' goober='1000'>tronic</baz></foo> would create field foo_bar_@goober=1000, skipping attribute baz [Default: []]</td>
  </tr>
  <tr>
    <td>exclude_elements</td>
    <td>array</td>
    <td>Array of elements to skip when creating field names, e.g. [baz] when encountering field <foo><baz><bar>tronic</bar></baz></foo> would create field foo_bar, skipping element baz [Default: [], After: include_all_attributes, include_attributes]</td>
  </tr>
  <tr>
    <td>include_all_attributes</td>
    <td>boolean</td>
    <td>Boolean to consider and include all attributes when creating field names, e.g. if false, XML elements <foo><bar baz='42' goober='1000'>tronic</baz></foo> would result in field name foo_bar witdout attributes included. Note: tde use of all attributes for creating field names has tde tde potential to balloon rapidly, potentially encountering ElasticSearch field limit for an index, tderefore false by default. [Default: false, Before: include_attributes, exclude_attributes]</td>
    <td>include_attributes</td>
    <td>array</td>
    <td>Array of attributes to include when creating field names, despite setting of include_all_attributes, e.g. [baz] when encountering XML <foo><bar baz='42' goober='1000'>tronic</baz></foo> would create field foo_bar_@baz=42 [Default: [], Before: exclude_attributes, After: include_all_attributes]</td>
  </tr>
  <tr>
    <td>include_meta</td>
    <td>boolean</td>
    <td>Boolean to include xml2kvp_meta field witd output tdat contains all tdese configurations [Default: false]</td>
  </tr>
  <tr>
    <td>node_delim</td>
    <td>string</td>
    <td>String to use as delimiter between XML elements and attributes when creating field name, e.g. ___ will convert XML <foo><bar>tronic</bar></foo> to field name foo___bar [Default: _]</td>
  </tr>
  <tr>
    <td>ns_prefix_delim</td>
    <td>string</td>
    <td>String to use as delimiter between XML namespace prefixes and elements, e.g. | for tde XML <ns:foo><ns:bar>tronic</ns:bar></ns:foo> will create field name ns|foo_ns:bar. Note: a | pipe character is used to avoid using a colon in ElasticSearch fields, which can be problematic. [Default: |]</td>
  </tr>
  <tr>
    <td>remove_copied_key</td>
    <td>boolean</td>
    <td>Boolean to determine if originating field will be removed from output if tdat field is copied to anotder field [Default: true]</td>
  </tr>
  <tr>
    <td>remove_copied_value</td>
    <td>boolean</td>
    <td>Boolean to determine if value will be removed from originating field if tdat value is copied to anotder field [Default: false]</td>
  </tr>
  <tr>
    <td>remove_ns_prefix</td>
    <td>boolean</td>
    <td>Boolean to determine if XML namespace prefixes are removed from field names, e.g. if false, tde XML <ns:foo><ns:bar>tronic</ns:bar></ns:foo> will result in field name foo_bar witdout ns prefix [Default: true]</td>
  </tr>
  <tr>
    <td>self_describing</td>
    <td>boolean</td>
    <td>Boolean to include machine parsable information about delimeters used (reading right-to-left, delimeter and its lengtd in characters) as suffix to field name, e.g. if true, and node_delim is ___ and ns_prefix_delim is |, suffix will be ___3|1. Can be useful to reverse engineer field name when not re-parsed by XML2kvp. [Default: false]</td>
  </tr>
  <tr>
    <td>skip_attribute_ns_declarations</td>
    <td>boolean</td>
    <td>Boolean to remove namespace declarations as considered attributes when creating field names [Default: true]</td>
  </tr>
  <tr>
    <td>skip_repeating_values</td>
    <td>boolean</td>
    <td>Boolean to determine if a field is multivalued, if tdose values are allowed to repeat, e.g. if set to false, XML <foo><bar>42</bar><bar>42</bar></foo> would map to foo_bar:42, removing tde repeating instance of tdat value. [Default: true]</td>
  </tr>
  <tr>
    <td>skip_root</td>
    <td>boolean</td>
    <td>Boolean to determine if tde XML root element will be included in output field names [Default: false]</td>
  </tr>
  <tr>
    <td>split_values_on_all_fields</td>
    <td>[boolean,``string``]</td>
    <td>If present, string to use for splitting values from all fields, e.g. `` `` will convert single value a foo bar please into tde array of values [a,``foo``,``bar``,``please``] for tdat field [Default: false]</td>
  </tr>
  <tr>
    <td>split_values_on_fields</td>
    <td>object</td>
    <td>Key/value pairs of field names to split, and tde string to split on, e.g. foo_bar:, will split all values on field foo_bar on comma , [Default: {}]</td>
  </tr>
  <tr>
    <td>repeating_element_suffix_count</td>
    <td>boolean</td>
    <td>Boolean to suffix field name witd incrementing integer (after first instance, which does not receieve a suffix), e.g. XML <foo><bar>42</bar><bar>109</bar></foo> would map to foo_bar:42, foo_bar_#1:109 [Default: false, Overrides: skip_repeating_values]</td>
  </tr>
</table><br />

<h3>Saving and Reusing</h3>

<p>Field Mapper configurations may be saved, named, and re-used. This can be done anytime field mapper configurations are being set, e.g. when running a new Job, or re-indexing a previously run Job.</p><br />

<h3>Testing</h3>

<p>Field Mapping can also be tested against a single record, accessible from a Record’s page under the “Run/Test Scenarios for this Record” tab. The following is a screenshot of this testing page:</p> 

<table>
  <tr>
    <td><img src="images/Part15-09-TestingFieldMapper.jpg" alt="Testing field mapper configurations" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Testing Field Mapper Configurations</em></td>
  </tr>
</table

<p>In this screenshot, you can see a single Record is used as input, a Field Mapper Configurations applied, and the resulting mapped fields at the bottom.</p><br />

<h2>DPLA Bulk Data Compare</h2>

<p>This somewhat experimental feature gives you the ability to compare the Records from a Job with a downloaded and indexed bulk data dump from DPLA. These DPLA bulk data downloads can be managed on the Configurations page.</p> 

<p>When running a Job, a user may optionally select what bulk data download to compare against:</p> 

<table>
  <tr>
    <td><img src="images/Part15-10-DPLABulkDataDownloadComparison.jpg" alt="Selecting a DPLA Bulk Data Download comparison for a Job" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Selecting a DPLA Bulk Data Download comparison for a Job</em></td>
  </tr>
</table

<p>One of the more experimental features of Combine is to compare the Records from a Job (or, of course, multiple Jobs if they are Merged into one) against a bulk data download from DPLA.</p> 

<p>To use this function, S3 credentials must be added to the combine/localsettings.py settings file that allow for downloading of bulk data downloads from S3. Once the credentials have been added and Combine restarted, it is possible to download previous bulk data dumps. This can be done from the configuration page by clicking on “Download and Index Bulk Data”, then selecting a bulk data download from the long dropdown. When the button is clicked, this data set will be downloaded and indexed locally in ElasticSearch, all as a background task. This will be reflected in the table on the Configuration page as complete when the row reads “Downloaded and Indexed”:</p> 

<table>
  <tr>
    <td><img src="images/Part15-11-DPLABulkDataDownloadComparison.jpg" alt="Downloaded and indexed DPLA Bulk Data Download comparison" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Downloaded and indexed DPLA Bulk Data Download (DBDD)</em></td>
  </tr>
</table

<p>A comparison can be triggered from any Job’s optional parameters under the tab DPLA Bulk Data Compare. The comparison is performed by attempting to match a Record’s Record Identifier to the _id field in the DPLA Item document.</p> 

<p>Because this comparison is using the Record Identifier for matching, this is a great example of where a Record Identifier Transformation Scenario (RITS) can be a powerful tool to emulate or recreate a known or previous identifier pattern. So much so, it’s conceivable that passing a RITS along with the DPLA Bulk Data Compare – just to temporarily transform the Record Identifier for comparison’s sake, but not in the Combine Record itself – might make sense.</p> 

<table>
  <tr>
    <td><img src="images/Part15-12-DPLABulkDataResults.jpg" alt="Results of a DPLA Bulk Data Download comparison" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Results of a DPLA Bulk Data Download comparison</em></td>
  </tr>
</table

<p>If a DPLA Bulk Data Download was selected for comparison to a Job, the results will be shown in this tab. The example above shows a comparison between a Job of roughly 250,000 Records and a DPLA Bulk Data Download of comparable size.</p> 

<p>This feature is experimental, but Combine provides an ideal environment and “moment in time” within the greater metadata aggregation ecosystem for this kind of comparison.</p> 

<p>In this example, we are seeing that 185k Records were found in the DPLA data dump, and that 38k Records appear to be new. Without an example at hand, it is difficult to show, but it’s conceivable that by leaving Jobs in Combine, and then comparing them against a later DPLA data dump, one could confirm that all records do show up in the DPLA data.</p><br />

<h3>DPLA API Query</h3>

<table>
  <tr>
    <td><img src="images/Part15-13-DPLAAPIQuery.jpg" alt="Matching a Combine Record's indexed fields with a DPLA API query'" width="800" border="2"></td>
  </tr>
  <tr>
  	<td><em>Matching a Combine Record’s Indexed Fields with a DPLA API query</em></td>
  </tr>
</table

<p>When a mapping has been made to the DPLA isShownAt field from the Indexed Fields tab (or at the Job level), and if a DPLA API query is successful, a result will be shown here:</p> 

<p>Results from the DPLA API are parsed and presented here, with the full API JSON response at the bottom (not pictured here). This can be useful for:</p> 

<ul>
  <li>confirming existence of a Record in DPLA</li>
  <li>easily retrieving detailed DPLA API metadata about the item</li>
  <li>confirming that changes and transformations are propagating as expected</li>
</ul>




